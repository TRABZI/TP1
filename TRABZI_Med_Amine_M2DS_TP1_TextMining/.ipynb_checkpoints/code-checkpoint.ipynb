{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab #2 \n",
    "\n",
    "TRABZI Mohammed Amine\n",
    "\n",
    "Master 2 Data Sciene \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fxF4tX0x_Opc",
    "outputId": "eceb261a-cb7b-45d0-e435-a056f05fadb2"
   },
   "source": [
    "# Downloads & Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /home/amine/miniconda3/lib/python3.8/site-packages (3.8.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/amine/miniconda3/lib/python3.8/site-packages (from gensim) (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/amine/miniconda3/lib/python3.8/site-packages (from gensim) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /home/amine/miniconda3/lib/python3.8/site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/amine/miniconda3/lib/python3.8/site-packages (from gensim) (4.2.0)\n",
      "Requirement already satisfied: nltk in /home/amine/miniconda3/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: tqdm in /home/amine/miniconda3/lib/python3.8/site-packages (from nltk) (4.51.0)\n",
      "Requirement already satisfied: regex in /home/amine/miniconda3/lib/python3.8/site-packages (from nltk) (2020.11.13)\n",
      "Requirement already satisfied: joblib in /home/amine/miniconda3/lib/python3.8/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in /home/amine/miniconda3/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "/home/amine/miniconda3/bin/python: No module named spacy\n",
      "Collecting spacy\n",
      "  Downloading spacy-3.0.3-cp38-cp38-manylinux2014_x86_64.whl (12.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.9 MB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typer<0.4.0,>=0.3.0\n",
      "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.1\n",
      "  Downloading catalogue-2.0.1-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/amine/miniconda3/lib/python3.8/site-packages (from spacy) (1.20.1)\n",
      "Requirement already satisfied: setuptools in /home/amine/miniconda3/lib/python3.8/site-packages (from spacy) (50.3.1.post20201107)\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Downloading wasabi-0.8.2-py3-none-any.whl (23 kB)\n",
      "Collecting pydantic<1.8.0,>=1.7.1\n",
      "  Downloading pydantic-1.7.3-cp38-cp38-manylinux2014_x86_64.whl (12.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.2 MB 672 kB/s eta 0:00:01   |▏                               | 81 kB 1.6 MB/s eta 0:00:08     |█████████████                   | 4.9 MB 1.6 MB/s eta 0:00:05\n",
      "\u001b[?25hCollecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.5-cp38-cp38-manylinux2014_x86_64.whl (35 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.0\n",
      "  Downloading srsly-2.4.0-cp38-cp38-manylinux2014_x86_64.whl (458 kB)\n",
      "\u001b[K     |████████████████████████████████| 458 kB 682 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.5-cp38-cp38-manylinux2014_x86_64.whl (130 kB)\n",
      "\u001b[K     |████████████████████████████████| 130 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting thinc<8.1.0,>=8.0.0\n",
      "  Downloading thinc-8.0.1-cp38-cp38-manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /home/amine/.local/lib/python3.8/site-packages (from spacy) (2.11.2)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.5-cp38-cp38-manylinux2014_x86_64.whl (20 kB)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Downloading blis-0.7.4-cp38-cp38-manylinux2014_x86_64.whl (9.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.8 MB 735 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /home/amine/miniconda3/lib/python3.8/site-packages (from spacy) (2.24.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/amine/.local/lib/python3.8/site-packages (from spacy) (20.4)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.0\n",
      "  Downloading spacy_legacy-3.0.1-py2.py3-none-any.whl (7.0 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/amine/miniconda3/lib/python3.8/site-packages (from spacy) (4.51.0)\n",
      "Collecting pathy\n",
      "  Downloading pathy-0.4.0-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /home/amine/miniconda3/lib/python3.8/site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/amine/miniconda3/lib/python3.8/site-packages (from jinja2->spacy) (1.1.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/amine/miniconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/amine/miniconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/amine/miniconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/amine/miniconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/amine/miniconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: six in /home/amine/miniconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy) (1.15.0)\n",
      "Collecting smart-open<4.0.0,>=2.2.0\n",
      "  Downloading smart_open-3.0.0.tar.gz (113 kB)\n",
      "\u001b[K     |████████████████████████████████| 113 kB 779 kB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-3.0.0-py3-none-any.whl size=107095 sha256=cd00e766cb5ccdbb2a0e132b668d57f67c8448ee3e2de8d92fb3cb8ea1c80d72\n",
      "  Stored in directory: /home/amine/.cache/pip/wheels/11/73/9a/f91ac1f1816436b16423617c5be5db048697ff152a9c4346f2\n",
      "Successfully built smart-open\n",
      "Installing collected packages: typer, catalogue, wasabi, pydantic, cymem, srsly, murmurhash, preshed, blis, thinc, spacy-legacy, smart-open, pathy, spacy\n",
      "  Attempting uninstall: smart-open\n",
      "    Found existing installation: smart-open 4.2.0\n",
      "    Uninstalling smart-open-4.2.0:\n",
      "      Successfully uninstalled smart-open-4.2.0\n",
      "Successfully installed blis-0.7.4 catalogue-2.0.1 cymem-2.0.5 murmurhash-1.0.5 pathy-0.4.0 preshed-3.0.5 pydantic-1.7.3 smart-open-3.0.0 spacy-3.0.3 spacy-legacy-3.0.1 srsly-2.4.0 thinc-8.0.1 typer-0.3.2 wasabi-0.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim \n",
    "!pip install nltk\n",
    "!python -m spacy download en_core_web_sm\n",
    "!pip install spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-20 19:49:05--  https://perso.limsi.fr/neveol/TP_ISD2020.zip\n",
      "Résolution de perso.limsi.fr (perso.limsi.fr)… 129.175.134.198\n",
      "Connexion à perso.limsi.fr (perso.limsi.fr)|129.175.134.198|:443… connecté.\n",
      "requête HTTP transmise, en attente de la réponse… 200 OK\n",
      "Taille : 11397405 (11M) [application/zip]\n",
      "Enregistre : «TP_ISD2020.zip.1»\n",
      "\n",
      "TP_ISD2020.zip.1    100%[===================>]  10,87M   313KB/s    ds 32s     \n",
      "\n",
      "2021-02-20 19:49:37 (347 KB/s) - «TP_ISD2020.zip.1» enregistré [11397405/11397405]\n",
      "\n",
      "Archive:  TP_ISD2020.zip\n",
      "replace QUAERO_FrenchMed/EMEA/EMEAdev_layer1_ID.conll? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    }
   ],
   "source": [
    "!wget https://perso.limsi.fr/neveol/TP_ISD2020.zip\n",
    "!unzip TP_ISD2020.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3f91fc27b051>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFastText\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "import gensim\n",
    "import nltk\n",
    "import os\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText\n",
    "\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"maxent_ne_chunker\")\n",
    "nltk.download(\"words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NLvkF1n9_nZp",
    "outputId": "529e2e37-a044-4efb-8275-7731695a478c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FrenchPress_w2v_SKIPGRAM.vec.gz', 'FrenchPress_FastText_CBOW.vec.gz', 'run_ner_conll03.sh', 'embed', 'output', 'ner.py', 'FrenchMed_FastText_CBOW.vec.gz', 'README', 'parsing.py', 'FrenchMed_w2v_SKIPGRAM.vec.gz', 'run-ner-q6-20-half.sh', 'neuronlp2', '.run-ner-q6-20-half.sh.swo', 'quaero-100-demi.json', 'FrenchPress_w2v_CBOW.vec.gz', 'TP_ISD2020.zip', 'TRABZI_code_TP1.ipynb', 'pos_tagging.py', 'QUAERO', 'FrenchMed_w2v_CBOW.vec.gz', 'FrenchMed_w2v_CBOW.vec', 'QUAERO_FrenchPress-w2v.vec.gz', '.ipynb_checkpoints'] \n",
      "\n",
      "FrenchPress_FastText_CBOW.vec.gz ..... $PATH =  /home/amine/tp2/FrenchPress_FastText_CBOW.vec.gz \n",
      "\n",
      "output ..... $PATH =  /home/amine/tp2/output\n"
     ]
    }
   ],
   "source": [
    "directory=os.listdir()\n",
    "print(directory,\"\\n\")\n",
    "dir_PATH=os.path.abspath(directory[1])\n",
    "print(directory[1],\"..... $PATH = \",dir_PATH,\"\\n\")\n",
    "dir_PATH=os.path.abspath(directory[4])\n",
    "print(directory[4],\"..... $PATH = \",dir_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_text(sentence):\n",
    "    return [word.lower() for word in nltk.word_tokenize(sentence) if word.isalnum()]\n",
    "\n",
    "def tokenize_text(text):\n",
    "    return [filter_text(sentence) for sentence in nltk.sent_tokenize(text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUAERO_FrenchMed_traindev.ospl\n",
      "QUAERO_FrenchPress_traindev.ospl\n",
      "\n",
      "number of sentences in sentences_FrenchPress: 3000\n",
      "number of tokens in sentences_FrenchPress: 43067 \n",
      "\n",
      "number of sentences in sentences_FrenchMed: 43541\n",
      "number of tokens in sentences_FrenchMed: 1113538\n"
     ]
    }
   ],
   "source": [
    "sentences_FrenchPress=[]\n",
    "sentences_FrenchMed=[]\n",
    "\n",
    "text_=[\"QUAERO_FrenchMed_traindev.ospl\",\"QUAERO_FrenchPress_traindev.ospl\"]\n",
    "for root,directory,files in os.walk(\"QUAERO\"):\n",
    "    for filename in files:\n",
    "        if filename in text_[0]:\n",
    "            print(filename)\n",
    "            with open(os.path.join(root,filename),'r') as rf:\n",
    "                text=rf.read()\n",
    "                sentences_FrenchPress.extend(tokenize_text(text))\n",
    "                num_words_FrenchPress=filter_text(text)#nltk.word_tokenize(text)\n",
    "        elif filename in text_[1]:\n",
    "            print(filename)\n",
    "            with open(os.path.join(root,filename),'r') as rf:\n",
    "                text=rf.read()\n",
    "                sentences_FrenchMed.extend(tokenize_text(text))\n",
    "                num_words_FrenchMed=filter_text(text) #nltk.word_tokenize(text)\n",
    "                \n",
    "print(\"\\nnumber of sentences in sentences_FrenchPress:\",len(sentences_FrenchPress))\n",
    "print(\"number of tokens in sentences_FrenchPress:\",len(num_words_FrenchPress),\"\\n\")\n",
    "\n",
    "print(\"number of sentences in sentences_FrenchMed:\",len(sentences_FrenchMed))\n",
    "print(\"number of tokens in sentences_FrenchMed:\",len(num_words_FrenchMed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named  Entity Recognition , using spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp_txt = nlp(text[0:500000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Entities</th>\n",
       "      <th>Labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Patricia, Martin)</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Nicolas, Stoufflet)</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(France, Inter)</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(7)</td>\n",
       "      <td>CARDINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Simon, Tivolle)</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3809</th>\n",
       "      <td>(Jean, -, Marie, Le, Pen)</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3810</th>\n",
       "      <td>(Bruno, Mégret)</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3811</th>\n",
       "      <td>(Front, National)</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3812</th>\n",
       "      <td>(Charles, Millon)</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3813</th>\n",
       "      <td>(Rhône, /, Alpes)</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3814 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Entities    Labels\n",
       "0            (Patricia, Martin)    PERSON\n",
       "1          (Nicolas, Stoufflet)    PERSON\n",
       "2               (France, Inter)    PERSON\n",
       "3                           (7)  CARDINAL\n",
       "4              (Simon, Tivolle)    PERSON\n",
       "...                         ...       ...\n",
       "3809  (Jean, -, Marie, Le, Pen)    PERSON\n",
       "3810            (Bruno, Mégret)    PERSON\n",
       "3811          (Front, National)       ORG\n",
       "3812          (Charles, Millon)    PERSON\n",
       "3813          (Rhône, /, Alpes)       ORG\n",
       "\n",
       "[3814 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_list = []\n",
    "entities_list = []\n",
    "\n",
    "for ent in nlp_txt.ents:\n",
    "    labels_list.append(ent.label_)\n",
    "    entities_list.append(ent)\n",
    "df = pd.DataFrame({'Entities':entities_list,'Labels':labels_list})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab #1 : word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p1u7HOib_qEl",
    "outputId": "7e9244b1-6162-4a61-b829-f2f08cdb7617",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=9104, size=100, alpha=0.025)\n",
      "Word2Vec(vocab=9104, size=100, alpha=0.025)\n",
      "FastText(vocab=9104, size=100, alpha=0.025)\n",
      "Word2Vec(vocab=39654, size=100, alpha=0.025)\n",
      "Word2Vec(vocab=39654, size=100, alpha=0.025)\n",
      "FastText(vocab=39654, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "#sentences_FrenchMed = LineSentence(datapath('/home/amine/tp2/QUAERO_FrenchMed/QUAERO_FrenchMed_traindev.ospl'))\n",
    "#sentences_FrenchPress = LineSentence(datapath('/home/amine/tp2/QUAERO_FrenchPress/QUAERO_FrenchPress_traindev.ospl'))\n",
    "\n",
    "# (1) #French_Med\n",
    "\n",
    "#French_Med\n",
    "FrenchMed_w2v_CBOW = Word2Vec(sentences_FrenchMed, size=100, min_count=1, sg=0)\n",
    "print(FrenchMed_w2v_CBOW)\n",
    "\n",
    "FrenchMed_w2v_SKIPGRAM = Word2Vec(sentences_FrenchMed, size=100, min_count=1, sg=1)\n",
    "print(FrenchMed_w2v_SKIPGRAM)\n",
    "\n",
    "FrenchMed_FastText_CBOW = FastText(sentences_FrenchMed, size=100, min_count=1, sg=0)\n",
    "print(FrenchMed_FastText_CBOW)\n",
    "\n",
    "# (2) French_Press\n",
    "\n",
    "FrenchPress_w2v_CBOW = Word2Vec(sentences_FrenchPress, size=100, min_count=1, sg=0)\n",
    "print(FrenchPress_w2v_CBOW)\n",
    "\n",
    "FrenchPress_w2v_SKIPGRAM = Word2Vec(sentences_FrenchPress, size=100, min_count=1, sg=1)\n",
    "print(FrenchPress_w2v_SKIPGRAM)\n",
    "\n",
    "FrenchPress_FastText_CBOW = FastText(sentences_FrenchPress, size=100, min_count=1, sg=0)\n",
    "print(FrenchPress_FastText_CBOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FrenchMed_w2v_CBOW.wv.save_word2vec_format('FrenchMed_w2v_CBOW.vec.gz', binary=False)\n",
    "\n",
    "FrenchMed_w2v_CBOW.wv.save_word2vec_format('FrenchMed_w2v_CBOW.vec.gz', binary=False)\n",
    "FrenchMed_w2v_SKIPGRAM.wv.save_word2vec_format('FrenchMed_w2v_SKIPGRAM.vec.gz', binary=False)\n",
    "FrenchMed_FastText_CBOW.wv.save_word2vec_format('FrenchMed_FastText_CBOW.vec.gz', binary=False)\n",
    "FrenchPress_w2v_CBOW.wv.save_word2vec_format('FrenchPress_w2v_CBOW.vec.gz', binary=False)\n",
    "FrenchPress_w2v_SKIPGRAM.wv.save_word2vec_format('FrenchPress_w2v_SKIPGRAM.vec.gz', binary=False)\n",
    "FrenchPress_FastText_CBOW.wv.save_word2vec_format('FrenchPress_FastText_CBOW.vec.gz', binary=False)\n",
    "\n",
    "\n",
    "'''FrenchMed_w2v_CBOW.save('FrenchMed_w2v_CBOW.vec.gz')\n",
    "FrenchMed_w2v_SKIPGRAM.save('FrenchMed_w2v_SKIPGRAM.vec.gz')\n",
    "#FrenchMed_FastText_CBOW.save('FrenchMed_FastText_CBOW.p')\n",
    "FrenchPress_w2v_CBOW.save('FrenchPress_w2v_CBOW.vec.gz')\n",
    "FrenchPress_w2v_SKIPGRAM.save('FrenchPress_w2v_SKIPGRAM.vec.gz')\n",
    "#FrenchPress_FastText_CBOW.save('FrenchPress_FastText_CBOW.p')'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test embedding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hcOHZa-fg2tm",
    "outputId": "a6ed6680-ee51-4026-8351-61ec716d5ae6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> French_Med :\n",
      "\n",
      "\n",
      " patient :\n",
      "w2v CBOW  :  ['d', 'du', 'un', 'des', 'le', 'et', 'en', 'à', 'aux', 'l']\n",
      "w2v SKIPGRAM  :  ['symptômes', 'lemp', 'grossesse', 'également', 'refludan', 'qui', 'cette', 'avant', 'devra', 'recommandé']\n",
      "fast text CBOW  :  ['patiente', 'conscients', 'patients', 'appartient', 'présentaient', 'aient', 'parvient', 'maintient', 'avaient', 'soient']\n",
      "\n",
      " treatment :\n",
      "w2v CBOW  :  [None]\n",
      "w2v SKIPGRAM  :  [None]\n",
      "fast text CBOW  :  ['lentement', 'localement', 'seulement', 'traitment', 'décollement', 'généralement', 'enregistrement', 'avancement', 'également', 'hautement']\n",
      "\n",
      " disease :\n",
      "w2v CBOW  :  [None]\n",
      "w2v SKIPGRAM  :  [None]\n",
      "fast text CBOW  :  ['telle', 'alvéolaire', 'épidémiologie', 'presse', 'constrictive', 'une', 'perivasculaire', 'dispose', 'prostate', 'vasculaire']\n",
      "\n",
      " solution :\n",
      "w2v CBOW  :  ['ml', 'flacon', 'perfusion', 'mg', 'contient', '2', 'pour', '1', '5', 'chaque']\n",
      "w2v SKIPGRAM  :  ['contient', 'flacon', '100', 'chaque', 'g', 'μ', '2', '1', '20', '300']\n",
      "fast text CBOW  :  ['dissolution', 'évolution', 'evolution', 'dilution', 'pollution', 'élocution', 'solutions', 'exécution', 'substitution', 'institution']\n",
      "\n",
      " yellow :\n",
      "w2v CBOW  :  [None]\n",
      "w2v SKIPGRAM  :  [None]\n",
      "fast text CBOW  :  ['échec', 'excrétés', 'poplité', 'ratte', 'voie', 'hospitalisés', 'petit', 'générés', 'polysorbate', 'pèsent']\n",
      "\n",
      "\n",
      "\n",
      "--> French_Press :\n",
      "\n",
      "\n",
      " patient :\n",
      "w2v CBOW  :  ['effort', 'faux', 'airbus', 'délit', 'témoignait', 'potentiel', 'digne', 'edf', 'mesureur', 'effectuer']\n",
      "w2v SKIPGRAM  :  ['miracle', 'embauche', 'invalider', 'motivation', 'journalistique', 'flic', 'identification', 'circonstance', 'ordinateur', 'copier']\n",
      "fast text CBOW  :  ['patientent', 'soutient', 'détient', 'impatient', 'contient', 'coefficient', 'convient', 'prient', 'initient', 'abstient']\n",
      "\n",
      " treatment :\n",
      "w2v CBOW  :  [None]\n",
      "w2v SKIPGRAM  :  [None]\n",
      "fast text CBOW  :  ['sédiment', 'ment', 'fument', 'clément', 'joliment', 'rythment', 'dorment', 'ciment', 'calment', 'sentiment']\n",
      "\n",
      " disease :\n",
      "w2v CBOW  :  [None]\n",
      "w2v SKIPGRAM  :  [None]\n",
      "fast text CBOW  :  ['dise', 'diseuse', 'dispose', 'réalise', 'diabolise', 'diffuse', 'sensibilise', 'cruise', 'repose', 'plaise']\n",
      "\n",
      " solution :\n",
      "w2v CBOW  :  ['forme', 'règle', 'réponse', 'catastrophe', 'espèce', 'démarche', 'carte', 'seule', 'possibilité', 'dimension']\n",
      "w2v SKIPGRAM  :  ['règle', 'alternative', 'puissance', 'garantie', 'consensuelle', 'unie', 'difficulté', 'démocratie', 'crédibilité', 'morale']\n",
      "fast text CBOW  :  ['révolution', 'résolution', 'évolution', 'pollution', 'dilution', 'dissolution', 'caution', 'potion', 'ponctuation', 'formulation']\n",
      "\n",
      " yellow :\n",
      "w2v CBOW  :  [None]\n",
      "w2v SKIPGRAM  :  [None]\n",
      "fast text CBOW  :  ['shell', 'well', 'bellemar', 'mello', 'belley', 'melloul', 'kelly', 'bellynck', 'kella', 'sigonella']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "candidate_word_list=[\"patient\", \"treatment\", \"disease\", \"solution\", \"yellow\"]\n",
    "\n",
    "approaches=[\"w2v CBOW\", \"w2v SKIPGRAM\", \"fast text CBOW\"]\n",
    "\n",
    "corpora=[\"French_Med\",\"French_Press\"]\n",
    "\n",
    "\n",
    "models_French_Med = [FrenchMed_w2v_CBOW, FrenchMed_w2v_SKIPGRAM, FrenchMed_FastText_CBOW ]\n",
    "models_French_Press = [FrenchPress_w2v_CBOW, FrenchPress_w2v_SKIPGRAM , FrenchPress_FastText_CBOW]\n",
    "\n",
    "models=[]\n",
    "models.append(models_French_Med)\n",
    "models.append(models_French_Press)\n",
    "\n",
    "m=0\n",
    "for k in corpora:\n",
    "    print(\"\\n-->\",k,\":\\n\")\n",
    "    for i in candidate_word_list:\n",
    "        a=0\n",
    "        print(\"\\n\",i,\":\")\n",
    "        for j in models[m]:\n",
    "            try:\n",
    "                list_embeddings = [embeddings[0] for embeddings in j.wv.most_similar(i)]\n",
    "                print(approaches[a],\" : \",list_embeddings)\n",
    "            except:\n",
    "                list_embeddings=[]\n",
    "                print(approaches[a],\" : \",\"[None]\")\n",
    "            a+=1\n",
    "    m+=1\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FtZa1GJ5aqJ2",
    "outputId": "698ec1f2-e8a3-489b-d83d-5581b6ce9537"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['solution', 'patient']\n"
     ]
    }
   ],
   "source": [
    "# Looking for availability of candidate_word_list in the datasets\n",
    "search=[]\n",
    "number_of_sets=2\n",
    "for _ in range(number_of_sets):\n",
    "\n",
    "  for j in models_French_Med:\n",
    "    for i in j.wv.vocab:\n",
    "      if i in candidate_word_list:\n",
    "        if i not in search:\n",
    "          search.append(i)\n",
    "\n",
    "  for j in models_French_Press:\n",
    "    for i in j.wv.vocab:\n",
    "      if i in candidate_word_list:\n",
    "        if i not in search:\n",
    "          search.append(i)\n",
    "          \n",
    "print(search)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
